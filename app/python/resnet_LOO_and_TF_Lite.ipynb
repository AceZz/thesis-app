{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that:\n",
    "- you should use a GPU to run the foollowing code due to high training and testing time\n",
    "- using cloud computing is recommended\n",
    "- path relatives to saving the model are to be changed in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5uevZuPJjPP",
    "outputId": "b88fdb48-f5b4-4d13-a7d1-7763bd0f37f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-macosx_10_9_universal2.whl size=170545 sha256=09e41339feb3334c5bcfc88b80fb22be9fd14ccc1643cf02fa5f627a9350f9f6\n",
      "  Stored in directory: /Users/tristanstampfler/Library/Caches/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
      "Successfully built pickle5\n",
      "Installing collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.11\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/Users/tristanstampfler/Documents/ETH/0.Master_Thesis/4. Python/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.17.1-cp310-cp310-macosx_10_15_x86_64.whl (588 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.4/588.4 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.8)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.17.1 typeguard-2.13.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/Users/tristanstampfler/Documents/ETH/0.Master_Thesis/4. Python/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip3 install pickle5 #&> /dev/null\n",
    "!pip3 install tensorflow_addons #&> /dev/null\n",
    "import pickle5 as pickle\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLblYbRZKZrs"
   },
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "xy1pv_w5Mrnq"
   },
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "\n",
    "with open(path + 'adl_and_fall_data.pickle', 'rb') as handle:\n",
    "    data_raw = pickle.load(handle) #shape: (examples, time_series, channels)\n",
    "\n",
    "labels = pd.read_csv(path+'adl_and_fall_labels.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvAQagTmNp53"
   },
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "fZWfZ-hINyIl"
   },
   "outputs": [],
   "source": [
    "compression_factor = 1\n",
    "\n",
    "def moving_average(a, n=compression_factor) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "### Compress the timestamps\n",
    "features = []\n",
    "for k in range(data_raw.shape[2]):\n",
    "    data_feat_raw = data_raw[:,:,k]\n",
    "    data_feat = np.zeros((data_feat_raw.shape[0], data_feat_raw.shape[1]//compression_factor))\n",
    "    for i in range(len(data_feat_raw)):\n",
    "        data_feat[i] = moving_average(data_feat_raw[i],n=compression_factor)[::compression_factor]\n",
    "    data_feat = data_feat.reshape(data_feat.shape[0],data_feat.shape[1],1)\n",
    "    features.append(data_feat)\n",
    "    \n",
    "data = np.concatenate(features, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucsQ3F59Nymw"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_lhwNaHz4p9"
   },
   "source": [
    "#### Define Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "5H05js21OTGx"
   },
   "outputs": [],
   "source": [
    "### Original source code from https://github.com/hfawaz/dl-4-tsc\n",
    "class Classifier_RESNET:\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, \n",
    "                 load_weights=False, batch_size = 64, n_feature_maps = 128, subject = None):\n",
    "        self.n_feature_maps = n_feature_maps\n",
    "        self.output_directory = output_directory\n",
    "        if subject is not None:\n",
    "            self.subject = subject\n",
    "        if build == True:\n",
    "            self.model = self.build_model(input_shape, nb_classes)\n",
    "            self.verbose = verbose\n",
    "            self.batch_size = batch_size\n",
    "            if load_weights == True:\n",
    "                model_path = self.output_directory + f'best_model_subject_{subject}.hdf5'\n",
    "                self.model = keras.models.load_model(model_path)\n",
    "        return\n",
    "\n",
    "    def build_model(self, input_shape, nb_classes):\n",
    "        n_feature_maps = self.n_feature_maps\n",
    "        dropout_rate = 0.5\n",
    "        kernel_size_1 = 8\n",
    "        kernel_size_2 = 7\n",
    "        kernel_size_3 = 5\n",
    "\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        # BLOCK 1\n",
    "        conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=kernel_size_1, padding='same')(input_layer)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "        conv_x = keras.layers.Dropout(dropout_rate)(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=kernel_size_2, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "        conv_y = keras.layers.Dropout(dropout_rate)(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=kernel_size_2, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        # expand channels for the sum\n",
    "        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "        output_block_1 = keras.layers.Dropout(dropout_rate, seed=0)(output_block_1)\n",
    "\n",
    "        # BLOCK 2\n",
    "        conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=kernel_size_1, padding='same')(output_block_1)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "        conv_x = keras.layers.Dropout(dropout_rate)(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=kernel_size_2, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "        conv_y = keras.layers.Dropout(dropout_rate)(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=kernel_size_2, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        # expand channels for the sum\n",
    "        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "        output_block_2 = keras.layers.Dropout(dropout_rate, seed=0)(output_block_2)\n",
    "\n",
    "        # BLOCK 3\n",
    "        conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=kernel_size_1, padding='same')(output_block_2) #change here\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "        conv_x = keras.layers.Dropout(dropout_rate)(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=kernel_size_2, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "        conv_y = keras.layers.Dropout(dropout_rate)(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=kernel_size_2, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        # No need to expand channels because they are equal\n",
    "        shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "        output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "\n",
    "        # FINAL\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        file_path = self.output_directory + f'best_model_subject_{subject}.hdf5'\n",
    "\n",
    "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
    "                                                           save_best_only=True)\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "        self.callbacks = [reduce_lr, model_checkpoint]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, x_train, y_train, x_val, y_val, nb_epochs, class_weight=None):\n",
    "        if not tf.test.is_gpu_available:\n",
    "            print('error')\n",
    "            exit()\n",
    "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
    "        batch_size = self.batch_size\n",
    "        nb_epochs = nb_epochs\n",
    "\n",
    "        mini_batch_size = int(min(x_train.shape[0] / 10, batch_size))\n",
    "\n",
    "        hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n",
    "                              verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks,\n",
    "                             class_weight=class_weight)\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        model_path = self.output_directory + f'best_model_subject_{subject}.hdf5'\n",
    "        model = keras.models.load_model(model_path)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eELIfypd3sT6"
   },
   "source": [
    "## Leave-One-Subject-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "CzHm7Tz5tY0E"
   },
   "outputs": [],
   "source": [
    "def label_smoothing(y, alpha=0.1):\n",
    "    \"\"\"simple label smoothing\"\"\"\n",
    "    K = y.shape[1]\n",
    "    return y * (1-alpha) + alpha / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initiliaze log files\n",
    "network = 'resnet'\n",
    "subjects = np.arange(1,31)\n",
    "\n",
    "with open(f'sota/{network}/logs.txt','w') as f:\n",
    "    f.write('average logs\\n')\n",
    "    f.close()\n",
    "\n",
    "for subject in subjects:\n",
    "    with open(f'sota/{network}/logs_subject_{subject}.txt', 'w') as f:\n",
    "        f.write(f'subject {subject} logs\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "VaditNcJ3pI_",
    "outputId": "7c700c7e-105d-47af-fd08-bd213111191c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "45/45 [==============================] - 36s 732ms/step - loss: 2.0333 - accuracy: 0.4627 - val_loss: 1340.2064 - val_accuracy: 0.0495 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 33s 741ms/step - loss: 1.4873 - accuracy: 0.6428 - val_loss: 48.4784 - val_accuracy: 0.1094 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 1.3649 - accuracy: 0.6983 - val_loss: 11.7274 - val_accuracy: 0.1849 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 1.2553 - accuracy: 0.7458 - val_loss: 5.9837 - val_accuracy: 0.1354 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 1.1821 - accuracy: 0.7741 - val_loss: 5.0736 - val_accuracy: 0.1302 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 1.1264 - accuracy: 0.7964 - val_loss: 2.6160 - val_accuracy: 0.4036 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 1.0663 - accuracy: 0.8259 - val_loss: 2.0157 - val_accuracy: 0.5234 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 1.0196 - accuracy: 0.8454 - val_loss: 2.1436 - val_accuracy: 0.5260 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.9878 - accuracy: 0.8567 - val_loss: 1.9591 - val_accuracy: 0.5677 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.9600 - accuracy: 0.8699 - val_loss: 2.0620 - val_accuracy: 0.5573 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.9224 - accuracy: 0.8864 - val_loss: 1.9777 - val_accuracy: 0.5469 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.8973 - accuracy: 0.8974 - val_loss: 1.8372 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.8818 - accuracy: 0.9037 - val_loss: 1.8858 - val_accuracy: 0.5547 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.8714 - accuracy: 0.9086 - val_loss: 1.8135 - val_accuracy: 0.6042 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.8373 - accuracy: 0.9214 - val_loss: 1.8429 - val_accuracy: 0.5938 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.8237 - accuracy: 0.9293 - val_loss: 1.5824 - val_accuracy: 0.6198 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.8161 - accuracy: 0.9311 - val_loss: 1.6225 - val_accuracy: 0.6224 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.7957 - accuracy: 0.9442 - val_loss: 1.6886 - val_accuracy: 0.5911 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7819 - accuracy: 0.9455 - val_loss: 1.5566 - val_accuracy: 0.6302 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7612 - accuracy: 0.9559 - val_loss: 1.6433 - val_accuracy: 0.6198 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7575 - accuracy: 0.9545 - val_loss: 1.5438 - val_accuracy: 0.6536 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7412 - accuracy: 0.9622 - val_loss: 1.7273 - val_accuracy: 0.5990 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7349 - accuracy: 0.9663 - val_loss: 1.6219 - val_accuracy: 0.6823 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.7288 - accuracy: 0.9665 - val_loss: 1.5176 - val_accuracy: 0.7031 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.7223 - accuracy: 0.9682 - val_loss: 1.6363 - val_accuracy: 0.6068 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.7132 - accuracy: 0.9731 - val_loss: 1.6456 - val_accuracy: 0.6198 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.7099 - accuracy: 0.9751 - val_loss: 1.7212 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7010 - accuracy: 0.9779 - val_loss: 1.5576 - val_accuracy: 0.6380 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6945 - accuracy: 0.9785 - val_loss: 1.5323 - val_accuracy: 0.6380 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6861 - accuracy: 0.9832 - val_loss: 1.5395 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6852 - accuracy: 0.9824 - val_loss: 1.5641 - val_accuracy: 0.6745 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.6804 - accuracy: 0.9845 - val_loss: 1.6407 - val_accuracy: 0.6302 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6719 - accuracy: 0.9882 - val_loss: 1.5081 - val_accuracy: 0.6641 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6732 - accuracy: 0.9861 - val_loss: 1.4985 - val_accuracy: 0.6849 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6717 - accuracy: 0.9877 - val_loss: 1.5218 - val_accuracy: 0.6458 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6628 - accuracy: 0.9901 - val_loss: 1.4660 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6605 - accuracy: 0.9913 - val_loss: 1.5233 - val_accuracy: 0.6536 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.6577 - accuracy: 0.9912 - val_loss: 1.5017 - val_accuracy: 0.6484 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6560 - accuracy: 0.9904 - val_loss: 1.5558 - val_accuracy: 0.6432 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6535 - accuracy: 0.9928 - val_loss: 1.4471 - val_accuracy: 0.6693 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6486 - accuracy: 0.9933 - val_loss: 1.4463 - val_accuracy: 0.6615 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6467 - accuracy: 0.9927 - val_loss: 1.4053 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6462 - accuracy: 0.9940 - val_loss: 1.4207 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.6400 - accuracy: 0.9951 - val_loss: 1.3655 - val_accuracy: 0.7396 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6373 - accuracy: 0.9961 - val_loss: 1.2811 - val_accuracy: 0.7682 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6412 - accuracy: 0.9942 - val_loss: 1.5875 - val_accuracy: 0.6328 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6401 - accuracy: 0.9948 - val_loss: 1.4216 - val_accuracy: 0.6875 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6338 - accuracy: 0.9959 - val_loss: 1.3679 - val_accuracy: 0.7214 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6335 - accuracy: 0.9957 - val_loss: 1.4663 - val_accuracy: 0.7083 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6307 - accuracy: 0.9968 - val_loss: 1.4094 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6309 - accuracy: 0.9959 - val_loss: 1.4254 - val_accuracy: 0.6562 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6290 - accuracy: 0.9966 - val_loss: 1.4974 - val_accuracy: 0.6875 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6276 - accuracy: 0.9966 - val_loss: 1.3908 - val_accuracy: 0.7448 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6276 - accuracy: 0.9969 - val_loss: 1.3506 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6250 - accuracy: 0.9972 - val_loss: 1.4385 - val_accuracy: 0.7005 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6263 - accuracy: 0.9968 - val_loss: 1.3484 - val_accuracy: 0.7240 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6217 - accuracy: 0.9979 - val_loss: 1.3991 - val_accuracy: 0.7240 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6216 - accuracy: 0.9984 - val_loss: 1.3919 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6198 - accuracy: 0.9983 - val_loss: 1.3674 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6204 - accuracy: 0.9980 - val_loss: 1.3323 - val_accuracy: 0.7604 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6200 - accuracy: 0.9979 - val_loss: 1.3742 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6195 - accuracy: 0.9982 - val_loss: 1.3581 - val_accuracy: 0.6953 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6174 - accuracy: 0.9983 - val_loss: 1.3916 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6162 - accuracy: 0.9987 - val_loss: 1.3210 - val_accuracy: 0.7396 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6168 - accuracy: 0.9986 - val_loss: 1.3682 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6153 - accuracy: 0.9982 - val_loss: 1.3869 - val_accuracy: 0.7188 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6146 - accuracy: 0.9989 - val_loss: 1.4534 - val_accuracy: 0.6875 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6119 - accuracy: 0.9995 - val_loss: 1.3667 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6112 - accuracy: 0.9992 - val_loss: 1.3266 - val_accuracy: 0.7370 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6117 - accuracy: 0.9990 - val_loss: 1.3532 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.6130 - accuracy: 0.9986 - val_loss: 1.3422 - val_accuracy: 0.7422 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6119 - accuracy: 0.9988 - val_loss: 1.4127 - val_accuracy: 0.7188 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6101 - accuracy: 0.9993 - val_loss: 1.3467 - val_accuracy: 0.7422 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6072 - accuracy: 0.9995 - val_loss: 1.3427 - val_accuracy: 0.7370 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6084 - accuracy: 0.9991 - val_loss: 1.3452 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6073 - accuracy: 0.9994 - val_loss: 1.3922 - val_accuracy: 0.7240 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6084 - accuracy: 0.9994 - val_loss: 1.3391 - val_accuracy: 0.7396 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6076 - accuracy: 0.9990 - val_loss: 1.3039 - val_accuracy: 0.7318 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6066 - accuracy: 0.9996 - val_loss: 1.3070 - val_accuracy: 0.7682 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6052 - accuracy: 0.9997 - val_loss: 1.3448 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6071 - accuracy: 0.9991 - val_loss: 1.3545 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6068 - accuracy: 0.9995 - val_loss: 1.2766 - val_accuracy: 0.7552 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6047 - accuracy: 0.9996 - val_loss: 1.3458 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6056 - accuracy: 0.9992 - val_loss: 1.2837 - val_accuracy: 0.7318 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6041 - accuracy: 0.9995 - val_loss: 1.3489 - val_accuracy: 0.7370 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6038 - accuracy: 0.9997 - val_loss: 1.2546 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6032 - accuracy: 0.9996 - val_loss: 1.2866 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6031 - accuracy: 0.9997 - val_loss: 1.2814 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6034 - accuracy: 0.9994 - val_loss: 1.3387 - val_accuracy: 0.7396 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6022 - accuracy: 0.9994 - val_loss: 1.2870 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6008 - accuracy: 0.9998 - val_loss: 1.3324 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6017 - accuracy: 0.9996 - val_loss: 1.3704 - val_accuracy: 0.6927 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6020 - accuracy: 0.9999 - val_loss: 1.3440 - val_accuracy: 0.7109 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6000 - accuracy: 0.9998 - val_loss: 1.2816 - val_accuracy: 0.7292 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5999 - accuracy: 0.9997 - val_loss: 1.2727 - val_accuracy: 0.7552 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5998 - accuracy: 0.9996 - val_loss: 1.2830 - val_accuracy: 0.7344 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5987 - accuracy: 0.9998 - val_loss: 1.2412 - val_accuracy: 0.7604 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.5987 - accuracy: 0.9999 - val_loss: 1.3065 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.5972 - accuracy: 0.9999 - val_loss: 1.3118 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5986 - accuracy: 0.9999 - val_loss: 1.3206 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5999 - accuracy: 0.9994 - val_loss: 1.3029 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5985 - accuracy: 0.9999 - val_loss: 1.2944 - val_accuracy: 0.7656 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5977 - accuracy: 0.9999 - val_loss: 1.2969 - val_accuracy: 0.7214 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5992 - accuracy: 0.9997 - val_loss: 1.3933 - val_accuracy: 0.7083 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5981 - accuracy: 0.9997 - val_loss: 1.2593 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5970 - accuracy: 0.9996 - val_loss: 1.3219 - val_accuracy: 0.7135 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5956 - accuracy: 0.9999 - val_loss: 1.3377 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6017 - accuracy: 0.9991 - val_loss: 1.2840 - val_accuracy: 0.7396 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6004 - accuracy: 0.9991 - val_loss: 1.2611 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5991 - accuracy: 0.9997 - val_loss: 1.2122 - val_accuracy: 0.7812 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.5952 - accuracy: 0.9999 - val_loss: 1.2009 - val_accuracy: 0.7760 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.5938 - accuracy: 0.9997 - val_loss: 1.2736 - val_accuracy: 0.7682 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5943 - accuracy: 0.9998 - val_loss: 1.2753 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.5954 - accuracy: 0.9998 - val_loss: 1.2758 - val_accuracy: 0.7578 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5966 - accuracy: 0.9996 - val_loss: 1.2270 - val_accuracy: 0.7474 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5957 - accuracy: 0.9997 - val_loss: 1.2597 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5979 - accuracy: 0.9995 - val_loss: 1.2645 - val_accuracy: 0.7526 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5959 - accuracy: 1.0000 - val_loss: 1.2380 - val_accuracy: 0.7630 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5952 - accuracy: 0.9998 - val_loss: 1.2178 - val_accuracy: 0.7682 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5936 - accuracy: 0.9999 - val_loss: 1.2986 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 1/120\n",
      "44/44 [==============================] - 36s 762ms/step - loss: 2.0660 - accuracy: 0.4317 - val_loss: 1153.9962 - val_accuracy: 0.0943 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "44/44 [==============================] - 33s 755ms/step - loss: 1.5419 - accuracy: 0.6117 - val_loss: 114.6130 - val_accuracy: 0.1184 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 1.3883 - accuracy: 0.6765 - val_loss: 29.0366 - val_accuracy: 0.1492 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 1.2651 - accuracy: 0.7419 - val_loss: 11.1859 - val_accuracy: 0.1527 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 1.2075 - accuracy: 0.7614 - val_loss: 10.6163 - val_accuracy: 0.1578 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 1.1375 - accuracy: 0.7871 - val_loss: 4.4297 - val_accuracy: 0.2967 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 1.0808 - accuracy: 0.8138 - val_loss: 1.8993 - val_accuracy: 0.5403 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "44/44 [==============================] - 33s 754ms/step - loss: 1.0441 - accuracy: 0.8315 - val_loss: 2.1192 - val_accuracy: 0.4391 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "44/44 [==============================] - 33s 754ms/step - loss: 1.0068 - accuracy: 0.8466 - val_loss: 1.6916 - val_accuracy: 0.6158 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.9658 - accuracy: 0.8659 - val_loss: 1.3727 - val_accuracy: 0.7015 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.9357 - accuracy: 0.8808 - val_loss: 1.2905 - val_accuracy: 0.7547 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.9176 - accuracy: 0.8901 - val_loss: 1.4944 - val_accuracy: 0.6690 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.8873 - accuracy: 0.9013 - val_loss: 1.4404 - val_accuracy: 0.7273 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "44/44 [==============================] - 33s 756ms/step - loss: 0.8686 - accuracy: 0.9085 - val_loss: 1.8330 - val_accuracy: 0.4631 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.8571 - accuracy: 0.9149 - val_loss: 1.4094 - val_accuracy: 0.6672 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "44/44 [==============================] - 33s 754ms/step - loss: 0.8350 - accuracy: 0.9233 - val_loss: 1.3306 - val_accuracy: 0.7204 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.8180 - accuracy: 0.9297 - val_loss: 1.2318 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.8009 - accuracy: 0.9381 - val_loss: 1.3064 - val_accuracy: 0.7616 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.7867 - accuracy: 0.9463 - val_loss: 1.3758 - val_accuracy: 0.7753 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.7735 - accuracy: 0.9486 - val_loss: 1.3579 - val_accuracy: 0.7221 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "44/44 [==============================] - 33s 754ms/step - loss: 0.7553 - accuracy: 0.9599 - val_loss: 1.1787 - val_accuracy: 0.7736 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.7517 - accuracy: 0.9586 - val_loss: 1.2701 - val_accuracy: 0.7547 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.7371 - accuracy: 0.9655 - val_loss: 1.2101 - val_accuracy: 0.7822 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.7282 - accuracy: 0.9688 - val_loss: 1.1945 - val_accuracy: 0.7736 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "44/44 [==============================] - 33s 754ms/step - loss: 0.7197 - accuracy: 0.9692 - val_loss: 1.2073 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.7123 - accuracy: 0.9725 - val_loss: 1.1734 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.7150 - accuracy: 0.9728 - val_loss: 1.1939 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "44/44 [==============================] - 33s 754ms/step - loss: 0.7056 - accuracy: 0.9753 - val_loss: 1.2365 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.7047 - accuracy: 0.9759 - val_loss: 1.1690 - val_accuracy: 0.7787 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6953 - accuracy: 0.9782 - val_loss: 1.2180 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6862 - accuracy: 0.9823 - val_loss: 1.1130 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6785 - accuracy: 0.9860 - val_loss: 1.4175 - val_accuracy: 0.7256 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6811 - accuracy: 0.9833 - val_loss: 1.4297 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6756 - accuracy: 0.9867 - val_loss: 1.2868 - val_accuracy: 0.7564 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6703 - accuracy: 0.9869 - val_loss: 1.2117 - val_accuracy: 0.7873 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6630 - accuracy: 0.9895 - val_loss: 1.2231 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6647 - accuracy: 0.9882 - val_loss: 1.2439 - val_accuracy: 0.8130 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6621 - accuracy: 0.9895 - val_loss: 1.2132 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6596 - accuracy: 0.9888 - val_loss: 1.2551 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6513 - accuracy: 0.9912 - val_loss: 1.2915 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6465 - accuracy: 0.9937 - val_loss: 1.2438 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6474 - accuracy: 0.9923 - val_loss: 1.1920 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6471 - accuracy: 0.9933 - val_loss: 1.1285 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6454 - accuracy: 0.9931 - val_loss: 1.1909 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6434 - accuracy: 0.9944 - val_loss: 1.3812 - val_accuracy: 0.7461 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6403 - accuracy: 0.9950 - val_loss: 1.2556 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6374 - accuracy: 0.9952 - val_loss: 1.1976 - val_accuracy: 0.7890 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6356 - accuracy: 0.9964 - val_loss: 1.2161 - val_accuracy: 0.7839 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6338 - accuracy: 0.9958 - val_loss: 1.2331 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6294 - accuracy: 0.9977 - val_loss: 1.1970 - val_accuracy: 0.8062 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6288 - accuracy: 0.9964 - val_loss: 1.2180 - val_accuracy: 0.7890 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6285 - accuracy: 0.9970 - val_loss: 1.1187 - val_accuracy: 0.8045 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6288 - accuracy: 0.9964 - val_loss: 1.3052 - val_accuracy: 0.7684 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6271 - accuracy: 0.9970 - val_loss: 1.3150 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6245 - accuracy: 0.9979 - val_loss: 1.1648 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6246 - accuracy: 0.9971 - val_loss: 1.2312 - val_accuracy: 0.7633 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "44/44 [==============================] - 32s 728ms/step - loss: 0.6263 - accuracy: 0.9971 - val_loss: 1.2384 - val_accuracy: 0.8165 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6218 - accuracy: 0.9985 - val_loss: 1.1700 - val_accuracy: 0.8165 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6241 - accuracy: 0.9978 - val_loss: 1.2479 - val_accuracy: 0.8199 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6219 - accuracy: 0.9984 - val_loss: 1.2654 - val_accuracy: 0.7616 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6186 - accuracy: 0.9985 - val_loss: 1.0879 - val_accuracy: 0.8336 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6176 - accuracy: 0.9987 - val_loss: 1.2118 - val_accuracy: 0.7976 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6180 - accuracy: 0.9980 - val_loss: 1.3103 - val_accuracy: 0.7890 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6176 - accuracy: 0.9982 - val_loss: 1.1592 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "44/44 [==============================] - 33s 753ms/step - loss: 0.6156 - accuracy: 0.9984 - val_loss: 1.2079 - val_accuracy: 0.7856 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6161 - accuracy: 0.9982 - val_loss: 1.1937 - val_accuracy: 0.8045 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6142 - accuracy: 0.9994 - val_loss: 1.1463 - val_accuracy: 0.7890 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6109 - accuracy: 0.9993 - val_loss: 1.1371 - val_accuracy: 0.7839 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6105 - accuracy: 0.9993 - val_loss: 1.0743 - val_accuracy: 0.8336 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6110 - accuracy: 0.9996 - val_loss: 1.2266 - val_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6118 - accuracy: 0.9988 - val_loss: 1.1255 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6132 - accuracy: 0.9989 - val_loss: 1.1619 - val_accuracy: 0.8130 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6114 - accuracy: 0.9989 - val_loss: 1.1354 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.6148 - accuracy: 0.9986 - val_loss: 1.1551 - val_accuracy: 0.8148 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.6109 - accuracy: 0.9995 - val_loss: 1.1601 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "44/44 [==============================] - 33s 750ms/step - loss: 0.6097 - accuracy: 0.9994 - val_loss: 1.2169 - val_accuracy: 0.7804 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6091 - accuracy: 0.9996 - val_loss: 1.1718 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6094 - accuracy: 0.9997 - val_loss: 1.1860 - val_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6089 - accuracy: 0.9992 - val_loss: 1.1271 - val_accuracy: 0.8148 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6074 - accuracy: 0.9989 - val_loss: 1.1436 - val_accuracy: 0.8199 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6052 - accuracy: 0.9998 - val_loss: 1.1702 - val_accuracy: 0.7942 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6073 - accuracy: 0.9994 - val_loss: 1.2016 - val_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6074 - accuracy: 0.9992 - val_loss: 1.2523 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6058 - accuracy: 0.9996 - val_loss: 1.1452 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.6081 - accuracy: 0.9988 - val_loss: 1.1215 - val_accuracy: 0.7976 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.6060 - accuracy: 0.9996 - val_loss: 1.1632 - val_accuracy: 0.7804 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.6068 - accuracy: 0.9988 - val_loss: 1.1506 - val_accuracy: 0.7907 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.6052 - accuracy: 0.9996 - val_loss: 1.1455 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6043 - accuracy: 0.9991 - val_loss: 1.1959 - val_accuracy: 0.8130 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6037 - accuracy: 0.9995 - val_loss: 1.1359 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6027 - accuracy: 0.9998 - val_loss: 1.1538 - val_accuracy: 0.8165 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.6016 - accuracy: 0.9997 - val_loss: 1.1168 - val_accuracy: 0.8268 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6041 - accuracy: 0.9994 - val_loss: 1.1822 - val_accuracy: 0.8062 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6023 - accuracy: 0.9997 - val_loss: 1.1283 - val_accuracy: 0.7925 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.6000 - accuracy: 0.9998 - val_loss: 1.1058 - val_accuracy: 0.8233 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.6007 - accuracy: 0.9999 - val_loss: 1.1449 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.6009 - accuracy: 0.9996 - val_loss: 1.1713 - val_accuracy: 0.7907 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.5998 - accuracy: 0.9999 - val_loss: 1.2184 - val_accuracy: 0.7753 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6002 - accuracy: 0.9996 - val_loss: 1.2129 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.6000 - accuracy: 0.9998 - val_loss: 1.1641 - val_accuracy: 0.7907 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.5985 - accuracy: 0.9998 - val_loss: 1.1003 - val_accuracy: 0.8491 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.5982 - accuracy: 0.9999 - val_loss: 1.2258 - val_accuracy: 0.7787 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.5973 - accuracy: 0.9999 - val_loss: 1.2009 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.5968 - accuracy: 0.9999 - val_loss: 1.0906 - val_accuracy: 0.8285 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.5982 - accuracy: 0.9996 - val_loss: 1.1143 - val_accuracy: 0.8130 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "44/44 [==============================] - 32s 727ms/step - loss: 0.5976 - accuracy: 0.9999 - val_loss: 1.1890 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "44/44 [==============================] - 33s 752ms/step - loss: 0.5966 - accuracy: 0.9997 - val_loss: 1.2532 - val_accuracy: 0.7993 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.5972 - accuracy: 0.9999 - val_loss: 1.2474 - val_accuracy: 0.7479 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "44/44 [==============================] - 33s 751ms/step - loss: 0.5958 - accuracy: 0.9999 - val_loss: 1.1353 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.5972 - accuracy: 0.9997 - val_loss: 1.1561 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.5982 - accuracy: 0.9997 - val_loss: 1.1918 - val_accuracy: 0.8233 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "44/44 [==============================] - 32s 725ms/step - loss: 0.5985 - accuracy: 0.9998 - val_loss: 1.1445 - val_accuracy: 0.8165 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.5969 - accuracy: 0.9998 - val_loss: 1.1606 - val_accuracy: 0.8268 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.5987 - accuracy: 0.9996 - val_loss: 1.1844 - val_accuracy: 0.8027 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.5985 - accuracy: 0.9995 - val_loss: 1.1052 - val_accuracy: 0.8233 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.5986 - accuracy: 0.9997 - val_loss: 1.1080 - val_accuracy: 0.8456 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "44/44 [==============================] - 32s 724ms/step - loss: 0.5969 - accuracy: 0.9999 - val_loss: 1.1282 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "44/44 [==============================] - 33s 749ms/step - loss: 0.5955 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "44/44 [==============================] - 33s 748ms/step - loss: 0.5935 - accuracy: 1.0000 - val_loss: 1.1105 - val_accuracy: 0.8182 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "44/44 [==============================] - 32s 726ms/step - loss: 0.5951 - accuracy: 0.9999 - val_loss: 1.1413 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 1/120\n",
      "45/45 [==============================] - 37s 760ms/step - loss: 2.0237 - accuracy: 0.4431 - val_loss: 1556.7939 - val_accuracy: 0.0461 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.5220 - accuracy: 0.6313 - val_loss: 47.8206 - val_accuracy: 0.1447 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 1.4019 - accuracy: 0.6789 - val_loss: 9.5347 - val_accuracy: 0.1678 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.2840 - accuracy: 0.7343 - val_loss: 5.1231 - val_accuracy: 0.1612 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.1925 - accuracy: 0.7702 - val_loss: 2.9608 - val_accuracy: 0.2961 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 1.1268 - accuracy: 0.7979 - val_loss: 1.5339 - val_accuracy: 0.5855 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.0983 - accuracy: 0.8157 - val_loss: 1.6613 - val_accuracy: 0.5263 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.0445 - accuracy: 0.8322 - val_loss: 1.4354 - val_accuracy: 0.6447 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 1.0083 - accuracy: 0.8464 - val_loss: 1.8316 - val_accuracy: 0.5230 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.9684 - accuracy: 0.8664 - val_loss: 1.3526 - val_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.9341 - accuracy: 0.8790 - val_loss: 1.4349 - val_accuracy: 0.7303 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.9069 - accuracy: 0.8930 - val_loss: 1.2641 - val_accuracy: 0.7303 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8831 - accuracy: 0.9029 - val_loss: 1.2430 - val_accuracy: 0.7763 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8688 - accuracy: 0.9110 - val_loss: 1.1464 - val_accuracy: 0.8026 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8365 - accuracy: 0.9218 - val_loss: 1.0930 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8195 - accuracy: 0.9319 - val_loss: 1.1721 - val_accuracy: 0.8059 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8016 - accuracy: 0.9382 - val_loss: 1.1431 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7959 - accuracy: 0.9415 - val_loss: 1.1110 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7784 - accuracy: 0.9487 - val_loss: 0.9502 - val_accuracy: 0.8684 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7628 - accuracy: 0.9534 - val_loss: 1.0009 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.7485 - accuracy: 0.9602 - val_loss: 1.0437 - val_accuracy: 0.8651 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.7355 - accuracy: 0.9655 - val_loss: 1.1191 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.7302 - accuracy: 0.9661 - val_loss: 0.9702 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7243 - accuracy: 0.9688 - val_loss: 1.0629 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7167 - accuracy: 0.9726 - val_loss: 1.0060 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.7196 - accuracy: 0.9695 - val_loss: 0.9830 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7093 - accuracy: 0.9754 - val_loss: 1.0466 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6945 - accuracy: 0.9783 - val_loss: 1.1014 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6924 - accuracy: 0.9801 - val_loss: 1.0271 - val_accuracy: 0.8454 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6802 - accuracy: 0.9838 - val_loss: 1.0871 - val_accuracy: 0.8092 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6813 - accuracy: 0.9827 - val_loss: 1.0760 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6708 - accuracy: 0.9872 - val_loss: 1.2149 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6693 - accuracy: 0.9871 - val_loss: 1.0619 - val_accuracy: 0.8454 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6669 - accuracy: 0.9876 - val_loss: 1.0177 - val_accuracy: 0.8586 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6630 - accuracy: 0.9902 - val_loss: 1.0369 - val_accuracy: 0.8553 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6597 - accuracy: 0.9910 - val_loss: 1.0679 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6573 - accuracy: 0.9908 - val_loss: 1.0951 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6583 - accuracy: 0.9904 - val_loss: 1.0848 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6501 - accuracy: 0.9930 - val_loss: 1.1219 - val_accuracy: 0.7829 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6482 - accuracy: 0.9932 - val_loss: 1.0570 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6444 - accuracy: 0.9938 - val_loss: 1.1031 - val_accuracy: 0.7993 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6452 - accuracy: 0.9928 - val_loss: 1.1424 - val_accuracy: 0.7599 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6448 - accuracy: 0.9940 - val_loss: 1.1353 - val_accuracy: 0.7697 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6397 - accuracy: 0.9949 - val_loss: 1.0529 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6360 - accuracy: 0.9954 - val_loss: 1.0712 - val_accuracy: 0.8059 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6371 - accuracy: 0.9943 - val_loss: 1.0873 - val_accuracy: 0.8026 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6356 - accuracy: 0.9952 - val_loss: 1.0673 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6348 - accuracy: 0.9961 - val_loss: 1.0092 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6322 - accuracy: 0.9966 - val_loss: 1.0707 - val_accuracy: 0.7895 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6281 - accuracy: 0.9970 - val_loss: 1.1003 - val_accuracy: 0.8059 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6265 - accuracy: 0.9969 - val_loss: 1.1350 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6257 - accuracy: 0.9970 - val_loss: 1.1949 - val_accuracy: 0.7664 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6253 - accuracy: 0.9974 - val_loss: 1.0132 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6260 - accuracy: 0.9973 - val_loss: 1.0905 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6212 - accuracy: 0.9978 - val_loss: 1.1480 - val_accuracy: 0.7763 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6244 - accuracy: 0.9976 - val_loss: 1.0868 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6229 - accuracy: 0.9976 - val_loss: 1.1302 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6206 - accuracy: 0.9984 - val_loss: 1.0563 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6194 - accuracy: 0.9981 - val_loss: 1.1095 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6181 - accuracy: 0.9980 - val_loss: 0.9873 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6190 - accuracy: 0.9980 - val_loss: 1.0344 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6151 - accuracy: 0.9987 - val_loss: 1.1065 - val_accuracy: 0.7961 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6154 - accuracy: 0.9989 - val_loss: 1.0461 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6170 - accuracy: 0.9984 - val_loss: 1.0532 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6146 - accuracy: 0.9987 - val_loss: 1.0852 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6128 - accuracy: 0.9987 - val_loss: 1.0534 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6126 - accuracy: 0.9990 - val_loss: 1.0382 - val_accuracy: 0.8553 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6128 - accuracy: 0.9983 - val_loss: 1.0697 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6130 - accuracy: 0.9976 - val_loss: 1.0907 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6102 - accuracy: 0.9989 - val_loss: 1.1444 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6137 - accuracy: 0.9984 - val_loss: 1.1376 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6108 - accuracy: 0.9993 - val_loss: 1.0698 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6087 - accuracy: 0.9993 - val_loss: 0.9884 - val_accuracy: 0.8553 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6064 - accuracy: 0.9997 - val_loss: 1.1139 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6094 - accuracy: 0.9990 - val_loss: 1.0682 - val_accuracy: 0.7961 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6100 - accuracy: 0.9993 - val_loss: 1.0798 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6087 - accuracy: 0.9992 - val_loss: 1.0226 - val_accuracy: 0.8487 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6065 - accuracy: 0.9992 - val_loss: 1.0661 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6040 - accuracy: 0.9999 - val_loss: 1.0692 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6038 - accuracy: 0.9997 - val_loss: 1.0872 - val_accuracy: 0.7961 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6048 - accuracy: 0.9992 - val_loss: 1.0418 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6043 - accuracy: 0.9997 - val_loss: 1.0140 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6035 - accuracy: 0.9996 - val_loss: 1.0680 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6042 - accuracy: 0.9997 - val_loss: 1.0286 - val_accuracy: 0.8388 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6013 - accuracy: 0.9997 - val_loss: 1.0850 - val_accuracy: 0.7993 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6023 - accuracy: 0.9993 - val_loss: 1.0387 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6026 - accuracy: 0.9993 - val_loss: 1.0024 - val_accuracy: 0.8520 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6034 - accuracy: 0.9994 - val_loss: 1.0219 - val_accuracy: 0.8487 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6037 - accuracy: 0.9994 - val_loss: 1.0558 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6033 - accuracy: 0.9990 - val_loss: 1.0092 - val_accuracy: 0.8092 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6024 - accuracy: 0.9996 - val_loss: 1.1392 - val_accuracy: 0.7763 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.5999 - accuracy: 0.9997 - val_loss: 1.0093 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6005 - accuracy: 0.9998 - val_loss: 1.0677 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6023 - accuracy: 0.9997 - val_loss: 1.0798 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6002 - accuracy: 0.9997 - val_loss: 1.0703 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.5990 - accuracy: 0.9997 - val_loss: 1.1016 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6002 - accuracy: 0.9995 - val_loss: 1.0648 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.5999 - accuracy: 0.9997 - val_loss: 1.0248 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.5989 - accuracy: 0.9997 - val_loss: 1.0023 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5994 - accuracy: 0.9996 - val_loss: 1.1401 - val_accuracy: 0.7730 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5995 - accuracy: 0.9997 - val_loss: 1.0503 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5970 - accuracy: 0.9998 - val_loss: 1.0407 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5967 - accuracy: 0.9999 - val_loss: 1.0336 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6011 - accuracy: 0.9989 - val_loss: 1.0247 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6003 - accuracy: 0.9994 - val_loss: 1.0393 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6018 - accuracy: 0.9990 - val_loss: 1.0656 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5973 - accuracy: 0.9998 - val_loss: 1.0751 - val_accuracy: 0.8125 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5959 - accuracy: 0.9997 - val_loss: 1.0762 - val_accuracy: 0.8158 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5958 - accuracy: 0.9997 - val_loss: 1.0420 - val_accuracy: 0.8257 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5962 - accuracy: 0.9999 - val_loss: 1.0156 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5954 - accuracy: 0.9999 - val_loss: 1.0340 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.5946 - accuracy: 0.9998 - val_loss: 1.0420 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5948 - accuracy: 0.9998 - val_loss: 1.0468 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5950 - accuracy: 0.9998 - val_loss: 1.1121 - val_accuracy: 0.7895 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5971 - accuracy: 0.9997 - val_loss: 1.0375 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.5953 - accuracy: 0.9997 - val_loss: 1.1091 - val_accuracy: 0.7928 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5940 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5929 - accuracy: 0.9999 - val_loss: 1.0508 - val_accuracy: 0.8355 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5926 - accuracy: 1.0000 - val_loss: 0.9890 - val_accuracy: 0.8651 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.5915 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 1/120\n",
      "45/45 [==============================] - 37s 758ms/step - loss: 1.9370 - accuracy: 0.4650 - val_loss: 1077.7988 - val_accuracy: 0.0579 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.4886 - accuracy: 0.6349 - val_loss: 53.9483 - val_accuracy: 0.0514 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 1.3566 - accuracy: 0.6956 - val_loss: 8.2369 - val_accuracy: 0.0611 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 1.2492 - accuracy: 0.7443 - val_loss: 6.6953 - val_accuracy: 0.1608 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.1706 - accuracy: 0.7727 - val_loss: 4.2775 - val_accuracy: 0.1865 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.1024 - accuracy: 0.8014 - val_loss: 3.8725 - val_accuracy: 0.2058 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.0545 - accuracy: 0.8247 - val_loss: 3.0969 - val_accuracy: 0.3151 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.9962 - accuracy: 0.8521 - val_loss: 2.5444 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.9691 - accuracy: 0.8613 - val_loss: 3.1509 - val_accuracy: 0.2605 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.9368 - accuracy: 0.8787 - val_loss: 3.0195 - val_accuracy: 0.3087 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.9115 - accuracy: 0.8891 - val_loss: 2.9148 - val_accuracy: 0.3280 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8801 - accuracy: 0.9020 - val_loss: 2.7646 - val_accuracy: 0.2958 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.8594 - accuracy: 0.9137 - val_loss: 2.6285 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8330 - accuracy: 0.9212 - val_loss: 2.8005 - val_accuracy: 0.3248 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.8161 - accuracy: 0.9315 - val_loss: 3.0932 - val_accuracy: 0.3055 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7978 - accuracy: 0.9380 - val_loss: 2.5537 - val_accuracy: 0.4180 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7794 - accuracy: 0.9468 - val_loss: 2.7012 - val_accuracy: 0.3183 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7640 - accuracy: 0.9524 - val_loss: 2.5255 - val_accuracy: 0.3280 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7600 - accuracy: 0.9525 - val_loss: 2.5379 - val_accuracy: 0.3119 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7451 - accuracy: 0.9593 - val_loss: 2.5113 - val_accuracy: 0.3151 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7399 - accuracy: 0.9626 - val_loss: 2.7277 - val_accuracy: 0.2862 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7294 - accuracy: 0.9673 - val_loss: 2.6383 - val_accuracy: 0.3280 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7186 - accuracy: 0.9714 - val_loss: 2.8693 - val_accuracy: 0.3537 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.7088 - accuracy: 0.9744 - val_loss: 2.8439 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.7132 - accuracy: 0.9712 - val_loss: 2.9957 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6963 - accuracy: 0.9788 - val_loss: 2.8755 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6908 - accuracy: 0.9819 - val_loss: 2.6909 - val_accuracy: 0.3762 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6828 - accuracy: 0.9818 - val_loss: 2.6826 - val_accuracy: 0.3248 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.6773 - accuracy: 0.9847 - val_loss: 2.8357 - val_accuracy: 0.3376 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6705 - accuracy: 0.9854 - val_loss: 2.7189 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6637 - accuracy: 0.9886 - val_loss: 2.9630 - val_accuracy: 0.3119 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6650 - accuracy: 0.9884 - val_loss: 2.7294 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6625 - accuracy: 0.9888 - val_loss: 2.8624 - val_accuracy: 0.3891 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6608 - accuracy: 0.9893 - val_loss: 2.7272 - val_accuracy: 0.3376 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6561 - accuracy: 0.9903 - val_loss: 2.8767 - val_accuracy: 0.3891 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6504 - accuracy: 0.9921 - val_loss: 3.0858 - val_accuracy: 0.3537 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6508 - accuracy: 0.9922 - val_loss: 2.9023 - val_accuracy: 0.3183 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6481 - accuracy: 0.9937 - val_loss: 2.9767 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6444 - accuracy: 0.9931 - val_loss: 2.6395 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6415 - accuracy: 0.9939 - val_loss: 2.5541 - val_accuracy: 0.3248 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6409 - accuracy: 0.9937 - val_loss: 2.9314 - val_accuracy: 0.3505 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6370 - accuracy: 0.9962 - val_loss: 2.9053 - val_accuracy: 0.3248 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6361 - accuracy: 0.9946 - val_loss: 2.9778 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6400 - accuracy: 0.9938 - val_loss: 2.9821 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6357 - accuracy: 0.9953 - val_loss: 2.6381 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6316 - accuracy: 0.9953 - val_loss: 2.8645 - val_accuracy: 0.3762 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6284 - accuracy: 0.9958 - val_loss: 3.0981 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6289 - accuracy: 0.9958 - val_loss: 2.7007 - val_accuracy: 0.3633 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6265 - accuracy: 0.9969 - val_loss: 2.5170 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6262 - accuracy: 0.9972 - val_loss: 2.8184 - val_accuracy: 0.3151 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6252 - accuracy: 0.9966 - val_loss: 3.0279 - val_accuracy: 0.3826 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6259 - accuracy: 0.9973 - val_loss: 2.7202 - val_accuracy: 0.3537 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6232 - accuracy: 0.9979 - val_loss: 2.8599 - val_accuracy: 0.3762 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6200 - accuracy: 0.9982 - val_loss: 2.9225 - val_accuracy: 0.2830 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6218 - accuracy: 0.9976 - val_loss: 2.8481 - val_accuracy: 0.3183 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "45/45 [==============================] - 34s 760ms/step - loss: 0.6194 - accuracy: 0.9982 - val_loss: 2.7017 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6184 - accuracy: 0.9989 - val_loss: 2.7610 - val_accuracy: 0.3505 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6169 - accuracy: 0.9983 - val_loss: 2.5054 - val_accuracy: 0.4277 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6185 - accuracy: 0.9977 - val_loss: 2.7377 - val_accuracy: 0.3762 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6149 - accuracy: 0.9984 - val_loss: 2.7805 - val_accuracy: 0.3859 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6157 - accuracy: 0.9981 - val_loss: 2.8031 - val_accuracy: 0.3633 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6147 - accuracy: 0.9988 - val_loss: 2.6991 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6145 - accuracy: 0.9986 - val_loss: 2.6440 - val_accuracy: 0.3215 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6132 - accuracy: 0.9990 - val_loss: 2.7787 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6111 - accuracy: 0.9994 - val_loss: 2.5612 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6107 - accuracy: 0.9989 - val_loss: 2.8651 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6112 - accuracy: 0.9980 - val_loss: 2.9012 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6100 - accuracy: 0.9996 - val_loss: 2.5254 - val_accuracy: 0.3505 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6094 - accuracy: 0.9992 - val_loss: 2.4683 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6094 - accuracy: 0.9993 - val_loss: 2.8960 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6091 - accuracy: 0.9990 - val_loss: 2.5743 - val_accuracy: 0.3505 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6080 - accuracy: 0.9990 - val_loss: 2.6590 - val_accuracy: 0.3087 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6065 - accuracy: 0.9999 - val_loss: 2.5135 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6078 - accuracy: 0.9987 - val_loss: 2.5771 - val_accuracy: 0.3698 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6046 - accuracy: 0.9996 - val_loss: 2.5378 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6057 - accuracy: 0.9998 - val_loss: 2.7362 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6048 - accuracy: 0.9995 - val_loss: 2.7439 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6030 - accuracy: 0.9997 - val_loss: 2.5972 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6024 - accuracy: 0.9995 - val_loss: 2.4634 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6024 - accuracy: 0.9997 - val_loss: 2.7065 - val_accuracy: 0.3087 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6020 - accuracy: 0.9997 - val_loss: 2.7510 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6029 - accuracy: 0.9999 - val_loss: 2.7521 - val_accuracy: 0.3376 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6036 - accuracy: 0.9995 - val_loss: 2.5944 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6044 - accuracy: 0.9991 - val_loss: 2.5983 - val_accuracy: 0.3794 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6033 - accuracy: 0.9995 - val_loss: 2.6978 - val_accuracy: 0.2990 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6026 - accuracy: 0.9994 - val_loss: 2.3093 - val_accuracy: 0.3955 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6011 - accuracy: 0.9996 - val_loss: 2.4583 - val_accuracy: 0.2637 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6017 - accuracy: 0.9996 - val_loss: 2.5994 - val_accuracy: 0.3762 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6016 - accuracy: 0.9997 - val_loss: 2.5855 - val_accuracy: 0.3505 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6011 - accuracy: 0.9995 - val_loss: 2.6243 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6010 - accuracy: 0.9998 - val_loss: 2.4510 - val_accuracy: 0.3569 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5982 - accuracy: 0.9997 - val_loss: 2.5786 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5984 - accuracy: 0.9997 - val_loss: 2.7359 - val_accuracy: 0.3280 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6001 - accuracy: 0.9997 - val_loss: 2.6300 - val_accuracy: 0.3666 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6007 - accuracy: 0.9995 - val_loss: 2.9366 - val_accuracy: 0.3376 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6011 - accuracy: 0.9993 - val_loss: 2.7127 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5985 - accuracy: 0.9999 - val_loss: 2.4328 - val_accuracy: 0.3280 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5998 - accuracy: 0.9992 - val_loss: 2.4910 - val_accuracy: 0.3698 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6009 - accuracy: 0.9996 - val_loss: 2.6075 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5982 - accuracy: 0.9997 - val_loss: 2.3707 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.5961 - accuracy: 0.9999 - val_loss: 2.3345 - val_accuracy: 0.3730 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5969 - accuracy: 0.9999 - val_loss: 2.4393 - val_accuracy: 0.3569 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5965 - accuracy: 0.9998 - val_loss: 2.4741 - val_accuracy: 0.3569 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5944 - accuracy: 0.9997 - val_loss: 2.6031 - val_accuracy: 0.3666 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5947 - accuracy: 0.9999 - val_loss: 2.4275 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5958 - accuracy: 0.9999 - val_loss: 2.9293 - val_accuracy: 0.3215 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5958 - accuracy: 0.9992 - val_loss: 2.7270 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "45/45 [==============================] - 32s 722ms/step - loss: 0.5956 - accuracy: 0.9999 - val_loss: 2.7978 - val_accuracy: 0.3119 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "45/45 [==============================] - 32s 722ms/step - loss: 0.5960 - accuracy: 0.9997 - val_loss: 2.3786 - val_accuracy: 0.3055 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "45/45 [==============================] - 32s 721ms/step - loss: 0.5964 - accuracy: 0.9996 - val_loss: 2.5774 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "45/45 [==============================] - 32s 722ms/step - loss: 0.5953 - accuracy: 0.9998 - val_loss: 2.4830 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.5930 - accuracy: 1.0000 - val_loss: 2.5271 - val_accuracy: 0.3408 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "45/45 [==============================] - 32s 722ms/step - loss: 0.5950 - accuracy: 0.9996 - val_loss: 2.3515 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5932 - accuracy: 0.9997 - val_loss: 2.4718 - val_accuracy: 0.3312 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5943 - accuracy: 0.9999 - val_loss: 2.4418 - val_accuracy: 0.3569 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5941 - accuracy: 0.9997 - val_loss: 2.4476 - val_accuracy: 0.3601 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5941 - accuracy: 0.9999 - val_loss: 2.5097 - val_accuracy: 0.3569 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5928 - accuracy: 0.9999 - val_loss: 2.5265 - val_accuracy: 0.3055 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.5921 - accuracy: 0.9998 - val_loss: 2.4569 - val_accuracy: 0.3633 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "45/45 [==============================] - 32s 722ms/step - loss: 0.5937 - accuracy: 0.9999 - val_loss: 2.4510 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 1/120\n",
      "45/45 [==============================] - 37s 760ms/step - loss: 2.0990 - accuracy: 0.4311 - val_loss: 2175.2820 - val_accuracy: 0.0503 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 34s 753ms/step - loss: 1.5295 - accuracy: 0.6248 - val_loss: 142.6783 - val_accuracy: 0.0705 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.3909 - accuracy: 0.6875 - val_loss: 51.8741 - val_accuracy: 0.0671 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.2900 - accuracy: 0.7299 - val_loss: 24.2560 - val_accuracy: 0.0772 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.2070 - accuracy: 0.7652 - val_loss: 10.0867 - val_accuracy: 0.0839 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 1.1396 - accuracy: 0.7907 - val_loss: 3.8888 - val_accuracy: 0.2383 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.0915 - accuracy: 0.8146 - val_loss: 3.1054 - val_accuracy: 0.2550 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.0737 - accuracy: 0.8213 - val_loss: 3.2225 - val_accuracy: 0.4060 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 1.0133 - accuracy: 0.8472 - val_loss: 2.5203 - val_accuracy: 0.5168 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.9813 - accuracy: 0.8621 - val_loss: 1.4737 - val_accuracy: 0.6544 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.9486 - accuracy: 0.8754 - val_loss: 1.4071 - val_accuracy: 0.6779 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.9172 - accuracy: 0.8899 - val_loss: 1.4933 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.9053 - accuracy: 0.8962 - val_loss: 1.7030 - val_accuracy: 0.6275 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8740 - accuracy: 0.9073 - val_loss: 2.1153 - val_accuracy: 0.5604 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8637 - accuracy: 0.9117 - val_loss: 1.6905 - val_accuracy: 0.6174 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.8483 - accuracy: 0.9201 - val_loss: 1.4962 - val_accuracy: 0.7148 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8129 - accuracy: 0.9345 - val_loss: 1.4095 - val_accuracy: 0.6946 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.8060 - accuracy: 0.9352 - val_loss: 1.2902 - val_accuracy: 0.7617 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7992 - accuracy: 0.9390 - val_loss: 1.4171 - val_accuracy: 0.7013 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7740 - accuracy: 0.9513 - val_loss: 1.3777 - val_accuracy: 0.7148 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7617 - accuracy: 0.9556 - val_loss: 1.3825 - val_accuracy: 0.6745 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.7637 - accuracy: 0.9526 - val_loss: 1.3438 - val_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.7491 - accuracy: 0.9598 - val_loss: 1.3072 - val_accuracy: 0.7315 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7324 - accuracy: 0.9657 - val_loss: 1.2812 - val_accuracy: 0.7752 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7233 - accuracy: 0.9714 - val_loss: 1.4045 - val_accuracy: 0.7248 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7124 - accuracy: 0.9765 - val_loss: 1.5158 - val_accuracy: 0.6980 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7085 - accuracy: 0.9745 - val_loss: 1.4265 - val_accuracy: 0.7383 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.7022 - accuracy: 0.9770 - val_loss: 1.4415 - val_accuracy: 0.7148 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.7068 - accuracy: 0.9768 - val_loss: 1.2626 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.6935 - accuracy: 0.9816 - val_loss: 1.3119 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6878 - accuracy: 0.9835 - val_loss: 1.2530 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6798 - accuracy: 0.9844 - val_loss: 1.2642 - val_accuracy: 0.7349 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6827 - accuracy: 0.9841 - val_loss: 1.3945 - val_accuracy: 0.7349 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.6781 - accuracy: 0.9852 - val_loss: 1.4156 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6764 - accuracy: 0.9847 - val_loss: 1.3723 - val_accuracy: 0.7550 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6676 - accuracy: 0.9897 - val_loss: 1.3154 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6642 - accuracy: 0.9891 - val_loss: 1.2973 - val_accuracy: 0.7651 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6620 - accuracy: 0.9889 - val_loss: 1.3574 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6589 - accuracy: 0.9910 - val_loss: 1.2424 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6570 - accuracy: 0.9910 - val_loss: 1.3061 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6555 - accuracy: 0.9915 - val_loss: 1.2230 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6475 - accuracy: 0.9942 - val_loss: 1.2536 - val_accuracy: 0.7752 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6476 - accuracy: 0.9929 - val_loss: 1.2989 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6473 - accuracy: 0.9936 - val_loss: 1.3598 - val_accuracy: 0.7651 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6431 - accuracy: 0.9942 - val_loss: 1.4130 - val_accuracy: 0.7248 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6433 - accuracy: 0.9948 - val_loss: 1.2967 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6399 - accuracy: 0.9955 - val_loss: 1.2794 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6410 - accuracy: 0.9945 - val_loss: 1.3034 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6393 - accuracy: 0.9951 - val_loss: 1.2179 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6383 - accuracy: 0.9947 - val_loss: 1.3502 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6357 - accuracy: 0.9951 - val_loss: 1.2904 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6306 - accuracy: 0.9973 - val_loss: 1.3139 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6287 - accuracy: 0.9979 - val_loss: 1.3059 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6288 - accuracy: 0.9963 - val_loss: 1.3244 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6273 - accuracy: 0.9969 - val_loss: 1.2458 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6249 - accuracy: 0.9978 - val_loss: 1.3210 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6244 - accuracy: 0.9974 - val_loss: 1.2422 - val_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6265 - accuracy: 0.9972 - val_loss: 1.2486 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6232 - accuracy: 0.9976 - val_loss: 1.2322 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6246 - accuracy: 0.9972 - val_loss: 1.2330 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6238 - accuracy: 0.9973 - val_loss: 1.2784 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6192 - accuracy: 0.9978 - val_loss: 1.2042 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6198 - accuracy: 0.9984 - val_loss: 1.2882 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6211 - accuracy: 0.9976 - val_loss: 1.2225 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "45/45 [==============================] - 34s 751ms/step - loss: 0.6174 - accuracy: 0.9985 - val_loss: 1.2681 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6192 - accuracy: 0.9976 - val_loss: 1.2489 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6155 - accuracy: 0.9989 - val_loss: 1.2547 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6142 - accuracy: 0.9992 - val_loss: 1.3124 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "45/45 [==============================] - 34s 752ms/step - loss: 0.6122 - accuracy: 0.9992 - val_loss: 1.1679 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6138 - accuracy: 0.9983 - val_loss: 1.2896 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6144 - accuracy: 0.9985 - val_loss: 1.2767 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6153 - accuracy: 0.9988 - val_loss: 1.2039 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6125 - accuracy: 0.9990 - val_loss: 1.2615 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6131 - accuracy: 0.9988 - val_loss: 1.2222 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6109 - accuracy: 0.9991 - val_loss: 1.2916 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6088 - accuracy: 0.9995 - val_loss: 1.2326 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6111 - accuracy: 0.9988 - val_loss: 1.2469 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6086 - accuracy: 0.9997 - val_loss: 1.1797 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6102 - accuracy: 0.9989 - val_loss: 1.2397 - val_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6094 - accuracy: 0.9996 - val_loss: 1.2357 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6067 - accuracy: 0.9993 - val_loss: 1.2327 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6051 - accuracy: 0.9998 - val_loss: 1.1824 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6063 - accuracy: 0.9993 - val_loss: 1.1934 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6057 - accuracy: 0.9991 - val_loss: 1.2083 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6047 - accuracy: 0.9997 - val_loss: 1.2210 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6045 - accuracy: 0.9997 - val_loss: 1.1950 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6035 - accuracy: 0.9994 - val_loss: 1.2110 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6055 - accuracy: 0.9990 - val_loss: 1.2218 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6076 - accuracy: 0.9992 - val_loss: 1.2318 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6039 - accuracy: 0.9997 - val_loss: 1.1751 - val_accuracy: 0.8188 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6039 - accuracy: 0.9994 - val_loss: 1.1377 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.6012 - accuracy: 0.9999 - val_loss: 1.2136 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6020 - accuracy: 0.9995 - val_loss: 1.2703 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6024 - accuracy: 0.9994 - val_loss: 1.1869 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.6022 - accuracy: 0.9998 - val_loss: 1.2019 - val_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6024 - accuracy: 0.9999 - val_loss: 1.1647 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.6004 - accuracy: 0.9996 - val_loss: 1.1424 - val_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6009 - accuracy: 0.9998 - val_loss: 1.1761 - val_accuracy: 0.8221 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "45/45 [==============================] - 33s 726ms/step - loss: 0.6011 - accuracy: 1.0000 - val_loss: 1.2173 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6006 - accuracy: 0.9997 - val_loss: 1.2042 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6021 - accuracy: 0.9990 - val_loss: 1.1429 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.6029 - accuracy: 0.9995 - val_loss: 1.1844 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6001 - accuracy: 0.9998 - val_loss: 1.2226 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5989 - accuracy: 0.9997 - val_loss: 1.0919 - val_accuracy: 0.8054 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5994 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.5992 - accuracy: 0.9995 - val_loss: 1.2052 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5983 - accuracy: 0.9997 - val_loss: 1.1905 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5983 - accuracy: 0.9998 - val_loss: 1.2087 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.5971 - accuracy: 0.9998 - val_loss: 1.2627 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5997 - accuracy: 0.9994 - val_loss: 1.2429 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5985 - accuracy: 0.9999 - val_loss: 1.1896 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.5972 - accuracy: 0.9999 - val_loss: 1.2027 - val_accuracy: 0.8188 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.5957 - accuracy: 0.9999 - val_loss: 1.1514 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.5949 - accuracy: 0.9999 - val_loss: 1.2399 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5954 - accuracy: 0.9998 - val_loss: 1.1769 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "45/45 [==============================] - 33s 725ms/step - loss: 0.5977 - accuracy: 0.9999 - val_loss: 1.1887 - val_accuracy: 0.8188 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.5961 - accuracy: 1.0000 - val_loss: 1.2265 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5965 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.5968 - accuracy: 0.9997 - val_loss: 1.1804 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "45/45 [==============================] - 32s 722ms/step - loss: 0.5957 - accuracy: 0.9999 - val_loss: 1.1558 - val_accuracy: 0.8154 - lr: 0.0010\n",
      "Epoch 1/120\n",
      "45/45 [==============================] - 36s 752ms/step - loss: 2.0302 - accuracy: 0.4320 - val_loss: 1443.9399 - val_accuracy: 0.0558 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 1.5462 - accuracy: 0.6142 - val_loss: 63.7910 - val_accuracy: 0.0898 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 1.3966 - accuracy: 0.6751 - val_loss: 12.0051 - val_accuracy: 0.1748 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 34s 754ms/step - loss: 1.2785 - accuracy: 0.7332 - val_loss: 5.6777 - val_accuracy: 0.2112 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 1.1899 - accuracy: 0.7672 - val_loss: 4.2316 - val_accuracy: 0.2816 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 1.1199 - accuracy: 0.8044 - val_loss: 1.7584 - val_accuracy: 0.4830 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 1.0809 - accuracy: 0.8160 - val_loss: 1.5991 - val_accuracy: 0.6650 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 1.0188 - accuracy: 0.8480 - val_loss: 1.1716 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.9879 - accuracy: 0.8525 - val_loss: 1.0245 - val_accuracy: 0.8398 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.9544 - accuracy: 0.8718 - val_loss: 1.0906 - val_accuracy: 0.8325 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.9223 - accuracy: 0.8850 - val_loss: 1.0850 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.8936 - accuracy: 0.8978 - val_loss: 0.9985 - val_accuracy: 0.8277 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.8793 - accuracy: 0.9044 - val_loss: 0.9156 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.8427 - accuracy: 0.9221 - val_loss: 0.9344 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.8273 - accuracy: 0.9266 - val_loss: 1.0203 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.8057 - accuracy: 0.9360 - val_loss: 1.0927 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.8012 - accuracy: 0.9373 - val_loss: 0.9556 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.7754 - accuracy: 0.9503 - val_loss: 0.9903 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.7634 - accuracy: 0.9540 - val_loss: 1.0856 - val_accuracy: 0.8131 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.7594 - accuracy: 0.9548 - val_loss: 1.1068 - val_accuracy: 0.7451 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.7429 - accuracy: 0.9636 - val_loss: 0.9374 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.7398 - accuracy: 0.9651 - val_loss: 0.9823 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.7233 - accuracy: 0.9710 - val_loss: 0.9794 - val_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.7142 - accuracy: 0.9719 - val_loss: 1.0057 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.7040 - accuracy: 0.9776 - val_loss: 0.9653 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6959 - accuracy: 0.9816 - val_loss: 0.9079 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6974 - accuracy: 0.9782 - val_loss: 0.9403 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6905 - accuracy: 0.9799 - val_loss: 1.0111 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6822 - accuracy: 0.9843 - val_loss: 0.9958 - val_accuracy: 0.8374 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6772 - accuracy: 0.9863 - val_loss: 1.0181 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6726 - accuracy: 0.9867 - val_loss: 0.9928 - val_accuracy: 0.8544 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6700 - accuracy: 0.9870 - val_loss: 0.8741 - val_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6658 - accuracy: 0.9879 - val_loss: 0.9042 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 34s 747ms/step - loss: 0.6645 - accuracy: 0.9875 - val_loss: 0.9343 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6709 - accuracy: 0.9869 - val_loss: 0.9193 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6574 - accuracy: 0.9916 - val_loss: 0.9934 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6563 - accuracy: 0.9910 - val_loss: 0.9290 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6596 - accuracy: 0.9898 - val_loss: 0.9233 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6487 - accuracy: 0.9923 - val_loss: 0.9308 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6460 - accuracy: 0.9937 - val_loss: 0.9909 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6453 - accuracy: 0.9930 - val_loss: 0.8801 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 42/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6427 - accuracy: 0.9947 - val_loss: 0.9249 - val_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 43/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6463 - accuracy: 0.9929 - val_loss: 0.8922 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 44/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6410 - accuracy: 0.9945 - val_loss: 0.9067 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 45/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6352 - accuracy: 0.9949 - val_loss: 0.9317 - val_accuracy: 0.8568 - lr: 0.0010\n",
      "Epoch 46/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6325 - accuracy: 0.9965 - val_loss: 0.9627 - val_accuracy: 0.8786 - lr: 0.0010\n",
      "Epoch 47/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6336 - accuracy: 0.9960 - val_loss: 0.9095 - val_accuracy: 0.9005 - lr: 0.0010\n",
      "Epoch 48/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6307 - accuracy: 0.9965 - val_loss: 0.9186 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Epoch 49/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6281 - accuracy: 0.9974 - val_loss: 0.8810 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 50/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6283 - accuracy: 0.9975 - val_loss: 0.9096 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 51/120\n",
      "45/45 [==============================] - 34s 745ms/step - loss: 0.6251 - accuracy: 0.9972 - val_loss: 0.8719 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 52/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6241 - accuracy: 0.9979 - val_loss: 0.9132 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 53/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6225 - accuracy: 0.9985 - val_loss: 0.8853 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 54/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6243 - accuracy: 0.9971 - val_loss: 0.9102 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 55/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6232 - accuracy: 0.9972 - val_loss: 0.9505 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 56/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6206 - accuracy: 0.9982 - val_loss: 0.9237 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 57/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6187 - accuracy: 0.9983 - val_loss: 0.9442 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 58/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6175 - accuracy: 0.9984 - val_loss: 0.9050 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 59/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6197 - accuracy: 0.9988 - val_loss: 0.8988 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 60/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6209 - accuracy: 0.9978 - val_loss: 0.9573 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 61/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6199 - accuracy: 0.9972 - val_loss: 0.9549 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 62/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6231 - accuracy: 0.9966 - val_loss: 0.9737 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 63/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6150 - accuracy: 0.9988 - val_loss: 0.9139 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 64/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6166 - accuracy: 0.9981 - val_loss: 0.9025 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 65/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6148 - accuracy: 0.9986 - val_loss: 0.9704 - val_accuracy: 0.8786 - lr: 0.0010\n",
      "Epoch 66/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6146 - accuracy: 0.9988 - val_loss: 0.9148 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 67/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6105 - accuracy: 0.9990 - val_loss: 0.9400 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 68/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6141 - accuracy: 0.9989 - val_loss: 0.9106 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 69/120\n",
      "45/45 [==============================] - 32s 720ms/step - loss: 0.6109 - accuracy: 0.9993 - val_loss: 0.8991 - val_accuracy: 0.9199 - lr: 0.0010\n",
      "Epoch 70/120\n",
      "45/45 [==============================] - 33s 745ms/step - loss: 0.6077 - accuracy: 0.9996 - val_loss: 0.9076 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 71/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6079 - accuracy: 0.9996 - val_loss: 0.9042 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 72/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6066 - accuracy: 0.9996 - val_loss: 0.9622 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 73/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6085 - accuracy: 0.9992 - val_loss: 0.9364 - val_accuracy: 0.8641 - lr: 0.0010\n",
      "Epoch 74/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6078 - accuracy: 0.9989 - val_loss: 0.9317 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 75/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6095 - accuracy: 0.9990 - val_loss: 0.9319 - val_accuracy: 0.9005 - lr: 0.0010\n",
      "Epoch 76/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6083 - accuracy: 0.9995 - val_loss: 0.9320 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 77/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6082 - accuracy: 0.9994 - val_loss: 0.9131 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 78/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6075 - accuracy: 0.9989 - val_loss: 0.9250 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Epoch 79/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6047 - accuracy: 0.9997 - val_loss: 0.9260 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 80/120\n",
      "45/45 [==============================] - 33s 742ms/step - loss: 0.6034 - accuracy: 0.9997 - val_loss: 0.9267 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 81/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.6051 - accuracy: 0.9991 - val_loss: 0.8685 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 82/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6052 - accuracy: 0.9992 - val_loss: 0.9066 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 83/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6053 - accuracy: 0.9992 - val_loss: 0.9209 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 84/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6058 - accuracy: 0.9995 - val_loss: 0.8928 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 85/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6027 - accuracy: 0.9997 - val_loss: 0.9550 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 86/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.6025 - accuracy: 0.9996 - val_loss: 0.8905 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 87/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6050 - accuracy: 0.9993 - val_loss: 0.8729 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 88/120\n",
      "45/45 [==============================] - 34s 746ms/step - loss: 0.6020 - accuracy: 0.9997 - val_loss: 0.8782 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 89/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6030 - accuracy: 0.9994 - val_loss: 0.8967 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 90/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.6010 - accuracy: 0.9998 - val_loss: 0.9066 - val_accuracy: 0.9005 - lr: 0.0010\n",
      "Epoch 91/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6020 - accuracy: 0.9997 - val_loss: 0.9153 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 92/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.6012 - accuracy: 0.9998 - val_loss: 0.8945 - val_accuracy: 0.9005 - lr: 0.0010\n",
      "Epoch 93/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5994 - accuracy: 0.9998 - val_loss: 0.9060 - val_accuracy: 0.9102 - lr: 0.0010\n",
      "Epoch 94/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.6000 - accuracy: 0.9998 - val_loss: 0.8740 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 95/120\n",
      "45/45 [==============================] - 33s 744ms/step - loss: 0.5988 - accuracy: 0.9994 - val_loss: 0.8940 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 96/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.5985 - accuracy: 0.9997 - val_loss: 0.8850 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 97/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.5977 - accuracy: 0.9998 - val_loss: 0.8997 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 98/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.5973 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 99/120\n",
      "45/45 [==============================] - 33s 743ms/step - loss: 0.5960 - accuracy: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 100/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5961 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 101/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5985 - accuracy: 0.9994 - val_loss: 0.9021 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 102/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5972 - accuracy: 0.9999 - val_loss: 0.9089 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 103/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5969 - accuracy: 0.9998 - val_loss: 0.9366 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 104/120\n",
      "45/45 [==============================] - 33s 742ms/step - loss: 0.5957 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 105/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5995 - accuracy: 0.9993 - val_loss: 0.9291 - val_accuracy: 0.8568 - lr: 0.0010\n",
      "Epoch 106/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5976 - accuracy: 0.9996 - val_loss: 0.9350 - val_accuracy: 0.8689 - lr: 0.0010\n",
      "Epoch 107/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5968 - accuracy: 0.9998 - val_loss: 0.9288 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 108/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5983 - accuracy: 0.9996 - val_loss: 0.9256 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 109/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5986 - accuracy: 0.9996 - val_loss: 0.9315 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 110/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5963 - accuracy: 0.9999 - val_loss: 0.9152 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 111/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5973 - accuracy: 0.9998 - val_loss: 0.9248 - val_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 112/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5959 - accuracy: 0.9997 - val_loss: 0.8898 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 113/120\n",
      "45/45 [==============================] - 33s 741ms/step - loss: 0.5947 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 114/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5955 - accuracy: 0.9997 - val_loss: 0.9310 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 115/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5959 - accuracy: 0.9999 - val_loss: 0.9374 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 116/120\n",
      "45/45 [==============================] - 32s 718ms/step - loss: 0.5959 - accuracy: 0.9997 - val_loss: 0.9270 - val_accuracy: 0.8786 - lr: 0.0010\n",
      "Epoch 117/120\n",
      "45/45 [==============================] - 33s 741ms/step - loss: 0.5938 - accuracy: 0.9998 - val_loss: 0.9259 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 118/120\n",
      "45/45 [==============================] - 33s 741ms/step - loss: 0.5931 - accuracy: 0.9999 - val_loss: 0.9440 - val_accuracy: 0.8786 - lr: 0.0010\n",
      "Epoch 119/120\n",
      "45/45 [==============================] - 32s 717ms/step - loss: 0.5945 - accuracy: 0.9996 - val_loss: 0.9027 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 120/120\n",
      "45/45 [==============================] - 32s 719ms/step - loss: 0.5943 - accuracy: 0.9998 - val_loss: 0.8935 - val_accuracy: 0.9126 - lr: 0.0010\n",
      "Epoch 1/120\n",
      "45/45 [==============================] - 37s 757ms/step - loss: 1.9426 - accuracy: 0.4667 - val_loss: 926.6640 - val_accuracy: 0.0545 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.4984 - accuracy: 0.6317 - val_loss: 57.5479 - val_accuracy: 0.0848 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 1.3713 - accuracy: 0.6918 - val_loss: 11.2467 - val_accuracy: 0.0424 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 1.2636 - accuracy: 0.7367 - val_loss: 6.9410 - val_accuracy: 0.1939 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 1.1878 - accuracy: 0.7751 - val_loss: 3.8358 - val_accuracy: 0.2970 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 1.1239 - accuracy: 0.8042 - val_loss: 1.4798 - val_accuracy: 0.5909 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 1.0833 - accuracy: 0.8161 - val_loss: 1.5393 - val_accuracy: 0.6273 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 1.0366 - accuracy: 0.8379 - val_loss: 1.5853 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.9929 - accuracy: 0.8579 - val_loss: 1.4231 - val_accuracy: 0.6545 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.9554 - accuracy: 0.8715 - val_loss: 1.5722 - val_accuracy: 0.6212 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.9318 - accuracy: 0.8846 - val_loss: 1.4599 - val_accuracy: 0.7152 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "45/45 [==============================] - 34s 750ms/step - loss: 0.9027 - accuracy: 0.8928 - val_loss: 1.4187 - val_accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.8852 - accuracy: 0.9026 - val_loss: 1.4109 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.8561 - accuracy: 0.9209 - val_loss: 1.3150 - val_accuracy: 0.7212 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.8365 - accuracy: 0.9256 - val_loss: 1.3369 - val_accuracy: 0.7364 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.8056 - accuracy: 0.9393 - val_loss: 1.4774 - val_accuracy: 0.7121 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "45/45 [==============================] - 33s 724ms/step - loss: 0.8091 - accuracy: 0.9363 - val_loss: 1.3267 - val_accuracy: 0.7758 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.7910 - accuracy: 0.9434 - val_loss: 1.5317 - val_accuracy: 0.7061 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.7679 - accuracy: 0.9510 - val_loss: 1.2863 - val_accuracy: 0.7455 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.7543 - accuracy: 0.9584 - val_loss: 1.3650 - val_accuracy: 0.7242 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.7483 - accuracy: 0.9594 - val_loss: 1.2816 - val_accuracy: 0.7818 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.7391 - accuracy: 0.9665 - val_loss: 1.2911 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.7325 - accuracy: 0.9672 - val_loss: 1.3363 - val_accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.7188 - accuracy: 0.9732 - val_loss: 1.2748 - val_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.7150 - accuracy: 0.9736 - val_loss: 1.3866 - val_accuracy: 0.7364 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.7023 - accuracy: 0.9783 - val_loss: 1.3100 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.7013 - accuracy: 0.9793 - val_loss: 1.3696 - val_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6949 - accuracy: 0.9795 - val_loss: 1.2885 - val_accuracy: 0.7818 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6908 - accuracy: 0.9833 - val_loss: 1.2783 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6846 - accuracy: 0.9835 - val_loss: 1.3333 - val_accuracy: 0.7545 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6803 - accuracy: 0.9853 - val_loss: 1.3140 - val_accuracy: 0.7970 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6724 - accuracy: 0.9876 - val_loss: 1.3246 - val_accuracy: 0.7939 - lr: 0.0010\n",
      "Epoch 33/120\n",
      "45/45 [==============================] - 33s 723ms/step - loss: 0.6745 - accuracy: 0.9864 - val_loss: 1.3309 - val_accuracy: 0.7636 - lr: 0.0010\n",
      "Epoch 34/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6680 - accuracy: 0.9879 - val_loss: 1.2618 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 35/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6614 - accuracy: 0.9906 - val_loss: 1.3495 - val_accuracy: 0.7515 - lr: 0.0010\n",
      "Epoch 36/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6582 - accuracy: 0.9906 - val_loss: 1.2831 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 37/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6538 - accuracy: 0.9917 - val_loss: 1.3608 - val_accuracy: 0.7848 - lr: 0.0010\n",
      "Epoch 38/120\n",
      "45/45 [==============================] - 34s 749ms/step - loss: 0.6536 - accuracy: 0.9922 - val_loss: 1.2403 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Epoch 39/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6485 - accuracy: 0.9931 - val_loss: 1.3540 - val_accuracy: 0.7818 - lr: 0.0010\n",
      "Epoch 40/120\n",
      "45/45 [==============================] - 34s 748ms/step - loss: 0.6472 - accuracy: 0.9939 - val_loss: 1.2426 - val_accuracy: 0.8121 - lr: 0.0010\n",
      "Epoch 41/120\n",
      "22/45 [=============>................] - ETA: 16s - loss: 0.6460 - accuracy: 0.9931"
     ]
    }
   ],
   "source": [
    "multi_class = True\n",
    "sota = True #dont forget to add subject as args when instantiating resnet\n",
    "alpha = 0.1\n",
    "n_feature_maps = 256\n",
    "nb_epochs = 120\n",
    "load_weights = False\n",
    "batch_size = 256\n",
    "seed = 4\n",
    "verbose = True\n",
    "\n",
    "\n",
    "### Define data\n",
    "subsample = 1\n",
    "X = data[::subsample]\n",
    "if multi_class:\n",
    "    y = labels[::subsample]['(is_fall,label)'].to_numpy()\n",
    "else:\n",
    "    y = labels[::subsample]['is_fall'].to_numpy()\n",
    "y = y.reshape(y.shape[0])\n",
    "\n",
    "### Leave-One-Subject-Out Cross Validation\n",
    "labels_subjects = labels[::subsample]['subject'].to_numpy().reshape(-1)\n",
    "metrics = {}\n",
    "metrics['accuracy'] = []\n",
    "metrics['f1_score'] = []\n",
    "metrics['sensitivity'] = []\n",
    "metrics['specificity'] = []\n",
    "\n",
    "for subject in subjects:\n",
    "    subjects_val = np.array([subject])\n",
    "\n",
    "    mask = np.isin(labels_subjects,subjects_val)\n",
    "\n",
    "    X_train, y_train, X_val, y_val = X[~mask], y[~mask], X[mask], y[mask]\n",
    "\n",
    "    ### Transform the labels from integers to one hot vectors\n",
    "    enc = OneHotEncoder(categories='auto')\n",
    "    enc.fit(np.concatenate((y_train, y_val), axis=0).reshape(-1, 1))\n",
    "    y_train_oh = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "    y_val_oh = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
    "    y_train_oh = label_smoothing(y_train_oh, alpha)\n",
    "    y_val_oh = label_smoothing(y_val_oh, alpha)\n",
    "\n",
    "    ### Create network\n",
    "    if sota:\n",
    "        output_directory = f'sota/{network}/'\n",
    "    else:\n",
    "        output_directory = f'{network}/'\n",
    "    input_shape = X_train.shape[1:]\n",
    "    nb_classes = len(y_val_oh[0])\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    ### Train\n",
    "    if network == 'resnet' and sota:\n",
    "        clf = Classifier_RESNET(output_directory=output_directory, input_shape=input_shape, nb_classes=nb_classes,\\\n",
    "                          verbose=verbose, batch_size = batch_size, n_feature_maps = n_feature_maps, load_weights=load_weights, subject=subject)\n",
    "    elif network == 'resnet' and not sota:\n",
    "        clf = Classifier_RESNET(output_directory=output_directory, input_shape=input_shape, nb_classes=nb_classes,\\\n",
    "                          verbose=verbose, batch_size = 256, n_feature_maps = n_feature_maps, load_weights=False)\n",
    "        \n",
    "    clf.fit(X_train, y_train_oh, X_val, y_val_oh, nb_epochs)\n",
    "    y_pred_probs = clf.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    ### Compute metrics\n",
    "    if multi_class:\n",
    "        y_val = np.argmax(y_val_oh,axis=1)\n",
    "    accuracy = accuracy_score(y_val,y_pred)\n",
    "    f1 = f1_score(y_val,y_pred, average='weighted')\n",
    "    metrics['accuracy'].append(accuracy)\n",
    "    metrics['f1_score'].append(f1)\n",
    "    \n",
    "    with open(f'sota/{network}/logs_subject_{subject}.txt', 'a') as f:\n",
    "        f.write(f'accuracy: {np.round(accuracy,4)}\\n')\n",
    "        f.write(f'f1 score: {np.round(f1,4)}\\n')\n",
    "        f.close()\n",
    "\n",
    "    if not multi_class:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val,y_pred).ravel()\n",
    "        sensitivity = tp / (tp+fn)\n",
    "        specificity = tn / (tn+fp)\n",
    "        metrics['sensitivity'].append(sensitivity)\n",
    "        metrics['specificity'].append(specificity)\n",
    "\n",
    "print('\\n')\n",
    "print('accuracy: ' + str(np.round(np.average(metrics['accuracy']),4)))\n",
    "print('accuracy details: ' + str(metrics['accuracy']))\n",
    "print('f1_score: ' + str(np.round(np.average(metrics['f1_score']),4)))\n",
    "print('f1_score details: ' + str(metrics['f1_score']))\n",
    "\n",
    "accuracy = np.round(np.average(metrics['accuracy']),4)\n",
    "f1 = np.round(np.average(metrics['f1_score']),4)\n",
    "              \n",
    "with open(f'sota/{network}/logs.txt', 'w') as f:\n",
    "    f.write(f'accuracy: {accuracy}\\n')\n",
    "    f.write(f'f1 score: {f1}\\n')\n",
    "    f.close()\n",
    "\n",
    "if not multi_class:\n",
    "    print('sensitivity: ' + str(np.round(np.average(metrics['sensitivity']),4)))\n",
    "    print('specificity: ' + str(np.round(np.average(metrics['specificity']),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save model as TF Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'tflite/'\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_classes = len(y_val_oh[0])\n",
    "verbose = True\n",
    "nb_epochs = 100 #TBD\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "clf = Classifier_RESNET(output_directory=output_directory, input_shape=input_shape, nb_classes=nb_classes,\\\n",
    "                       verbose=verbose, n_feature_maps=256, batch_size = 256)\n",
    "\n",
    "clf.fit(X_train, y_train_oh, X_val, y_val_oh, nb_epochs)\n",
    "\n",
    "### Save model\n",
    "output_directory = 'models/' #TBD\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(output_directory + \"best_model.hdf5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(output_directory + \"model.tflite\", 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Vbsu6Z19XBIt",
    "bbzaKORMOjA5",
    "KCx0ozfs3qWB"
   ],
   "name": "Master Thesis - ResNet Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
